{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "run = \"resnet 18 high dropout\"\n",
        "run_title = r\"/content/runs/{0}\".format(run)"
      ],
      "metadata": {
        "id": "sRgJIbpk5cvH"
      },
      "id": "sRgJIbpk5cvH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uFPk1A5WB5Ks",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uFPk1A5WB5Ks",
        "outputId": "40a4a1f9-2add-469a-c4f9-2393a3f38e18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from os import getcwd\n",
        "\n",
        "getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bevAedm0-pIg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bevAedm0-pIg",
        "outputId": "ac865a2e-d04f-49fe-ab54-4044ef2c3b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "def is_colab():\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "file_prefix = ''\n",
        "if is_colab():\n",
        "    run_title = \"/content/drive/MyDrive/ringo/runs/\" + run\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    # Specify the path to the folder where the zip will be extracted\n",
        "    extracted_folder_path = 'ringo'\n",
        "    # Check if the folder already exists\n",
        "    if not os.path.exists(extracted_folder_path):\n",
        "        with zipfile.ZipFile('/content/drive/MyDrive/ringo/ringo.zip', 'r') as zip_ref:\n",
        "            zip_ref.extractall(extracted_folder_path)\n",
        "    # Optionally, you can unmount the drive once you are done with file operations\n",
        "    # drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define the source and destination paths\n",
        "source_path = '/content/drive/MyDrive/ringo/ringo_dataset.py'\n",
        "destination_path = 'ringo_dataset.py'\n",
        "\n",
        "# Check if the destination file already exists\n",
        "if not os.path.exists(destination_path):\n",
        "    # Copy the file\n",
        "    shutil.copy(source_path, destination_path)\n",
        "    print(f'File copied from {source_path} to {destination_path}')\n",
        "else:\n",
        "    print(f'The file {destination_path} already exists. No action taken.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv-u8roufl6I",
        "outputId": "ebddc17d-4a49-42bb-f4fc-ef2c8cb7c2b6"
      },
      "id": "Yv-u8roufl6I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The file ringo_dataset.py already exists. No action taken.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nYRtvaNrB_z0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nYRtvaNrB_z0",
        "outputId": "2eeb37ae-2afa-4ebb-ab26-4c6181cb141c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "os.chdir('/content')\n",
        "getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5139d81-9554-4d34-860c-f288cd016330",
      "metadata": {
        "id": "c5139d81-9554-4d34-860c-f288cd016330"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e72f527f-ad0a-47c9-994b-3a0d0ede83fa",
      "metadata": {
        "id": "e72f527f-ad0a-47c9-994b-3a0d0ede83fa"
      },
      "outputs": [],
      "source": [
        "from ringo_dataset import RingoDataset\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b19230d2-f2e4-4c8f-b25b-67f6ff3681ba",
      "metadata": {
        "id": "b19230d2-f2e4-4c8f-b25b-67f6ff3681ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3e0c798-0753-4963-8501-4d1b85f87c4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "looks like we've got a wimpy little cpu\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    run_title = run_title + \" (cuda)\"\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"We've got a graphics card!\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"looks like we've got a wimpy little cpu\")\n",
        "writer = SummaryWriter(run_title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c95eaafa-ae3a-4c6e-bbf0-64fc134b4cdb",
      "metadata": {
        "id": "c95eaafa-ae3a-4c6e-bbf0-64fc134b4cdb"
      },
      "outputs": [],
      "source": [
        "# Load the pre-defined model\n",
        "model = torchvision.models.resnet18()\n",
        "model = model.to(device)\n",
        "\n",
        "# Modify the classifier\n",
        "# Add ReLU activation followed by a linear layer from 1000 to 1\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(0.9),\n",
        "    model.fc,  # Original classifier layers\n",
        "    nn.ReLU(),           # Additional ReLU activation\n",
        "    nn.Linear(1000, 1)   # Additional Linear layer from 1000 to 1\n",
        ").to(device)\n",
        "\n",
        "# model = nn.Sequential(nn.Dropout(0.0).to(device), model)\n",
        "\n",
        "# model.load_state_dict(torch.load(\"autoaim_resnet 18 dropout 0.5 2 (no dropout now).pth\", map_location = device))\n",
        "\n",
        "# Create a test input\n",
        "# expects a 3 channel image, but the size can be flexible\n",
        "test_input = torch.randn(1, 3, 200, 200).to(device)  # Batch size of 1\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Forward pass through the model\n",
        "    output = model(test_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8361ab9c-5f95-472f-806f-743fe5456cf1",
      "metadata": {
        "id": "8361ab9c-5f95-472f-806f-743fe5456cf1"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "weight_decay = 0.0\n",
        "writer.add_text(\"info\", f\"learning rate: {learning_rate}\")\n",
        "\n",
        "optimizer = torch.optim.AdamW(lr = learning_rate, params = model.parameters(), weight_decay = weight_decay)\n",
        "\n",
        "criterion = torch.nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100"
      ],
      "metadata": {
        "id": "JroTqUKY6vtA"
      },
      "id": "JroTqUKY6vtA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print everything in the current working directory in python\n",
        "\n",
        "import os\n",
        "\n",
        "# Get the current working directory\n",
        "cwd = os.getcwd()\n",
        "\n",
        "# List all files and directories in the current working directory\n",
        "files_and_directories = os.listdir(cwd)\n",
        "\n",
        "# Print each file and directory\n",
        "for file_or_directory in files_and_directories:\n",
        "    print(file_or_directory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwcp8t0rE_hC",
        "outputId": "c28c7103-e83e-4066-a71b-97172cdd58db"
      },
      "id": "fwcp8t0rE_hC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".config\n",
            "ringo_dataset.py\n",
            "drive\n",
            "__pycache__\n",
            "ringo\n",
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed5a212f-4f73-4f80-9c2c-1a00a7733596",
      "metadata": {
        "id": "ed5a212f-4f73-4f80-9c2c-1a00a7733596",
        "outputId": "ecdd858f-cceb-4394-f94e-3723f4adb43f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading images...\n",
            "number of samples: 2959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2959/2959 [00:24<00:00, 119.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading images...\n",
            "number of samples: 735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 735/735 [00:05<00:00, 125.66it/s]\n"
          ]
        }
      ],
      "source": [
        "training_dataset = RingoDataset(r\"ringo/training\", aiming = True, image_limit = None)\n",
        "training_loader = torch.utils.data.DataLoader(training_dataset, batch_size = batch_size, shuffle = True)\n",
        "testing_dataset = RingoDataset(r\"ringo/testing\", aiming = True, image_limit = None)\n",
        "testing_loader = torch.utils.data.DataLoader(testing_dataset, batch_size = batch_size, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cc4005c-9ae9-4dab-a43f-08fbbefde97e",
      "metadata": {
        "id": "5cc4005c-9ae9-4dab-a43f-08fbbefde97e",
        "outputId": "a96bb8ef-e8d1-4eb4-c0e8-af2a2e30d878",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3426]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# test a sample to make sure that the model's shapes work out\n",
        "some_image_sample = training_dataset[0][0].to(device)\n",
        "model(training_dataset[0][0].unsqueeze(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d303975c-30c9-4a7b-8be6-a6bef27543b3",
      "metadata": {
        "id": "d303975c-30c9-4a7b-8be6-a6bef27543b3"
      },
      "outputs": [],
      "source": [
        "def test(model, criterion, testing_loader, epoch):\n",
        "    with torch.no_grad():\n",
        "        total_loss = 0\n",
        "        total_batches = 0\n",
        "        correct = 0\n",
        "        almost_correct = 0\n",
        "        not_really_correct = 0\n",
        "        wrong = 0\n",
        "        samples = 0\n",
        "        for batch in testing_loader:\n",
        "            total_batches += 1\n",
        "            images, stamp_types, inside_diameters, y_offsets = batch\n",
        "            y_offsets = y_offsets.unsqueeze(1).to(device) # TODO: also fix this? >.> (is it because there's no channel dim?)\n",
        "            output = model(images)\n",
        "            # print(output, y_offsets)\n",
        "            for some_output, some_y_offset in zip(output, y_offsets):\n",
        "                samples += 1\n",
        "                difference = torch.abs(torch.round(some_output[0], decimals=1) - some_y_offset[0])\n",
        "                if difference < 0.1:\n",
        "                    correct += 1\n",
        "                if difference < 0.2:\n",
        "                    almost_correct += 1\n",
        "                if difference < 0.3:\n",
        "                    not_really_correct += 1\n",
        "                else:\n",
        "                    wrong += 1\n",
        "            loss = criterion(output, y_offsets)\n",
        "            total_loss += loss\n",
        "        writer.add_scalar(\"accuracy/correct within 0.1\", correct / samples, epoch)\n",
        "        writer.add_scalar(\"accuracy/corrent within 0.2\", almost_correct / samples, epoch)\n",
        "        writer.add_scalar(\"accuracy/correct within 0.3\", not_really_correct / samples, epoch)\n",
        "        writer.add_scalar(\"accuracy/more than 0.3\", wrong / samples, epoch)\n",
        "    return total_loss / total_batches"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: display tensorboard\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=/content/drive/MyDrive/ringo/runs\n"
      ],
      "metadata": {
        "id": "e65NJql3Ge8e"
      },
      "id": "e65NJql3Ge8e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1392322-edda-4d93-9847-58d73b6777d6",
      "metadata": {
        "id": "c1392322-edda-4d93-9847-58d73b6777d6",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eaf12ce-9128-46a1-d319-e0b017671aee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "welcome to epoch: 1\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(\"welcome to epoch:\", epoch + 1)\n",
        "    batch_count = 0\n",
        "    total_loss = 0\n",
        "    for i, batch in enumerate(training_loader):\n",
        "        # print(\"Batch:\", i + 1)\n",
        "        batch_count += 1\n",
        "        optimizer.zero_grad()\n",
        "        image, stamp_type, inside_diameter, y_offset = batch\n",
        "        y_offset = y_offset.unsqueeze(1) # fix this... >.>\n",
        "        output = model(image)\n",
        "        # print(output.shape, y_offset.shape)\n",
        "        # print(\"outputs vs. expected_outputs:\")\n",
        "        loss = criterion(output, y_offset)\n",
        "        total_loss += loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    average_training_loss = total_loss / batch_count\n",
        "    writer.add_scalar(\"loss/training\", average_training_loss, epoch)\n",
        "    test_loss = test(model, criterion, testing_loader, epoch)\n",
        "    writer.add_scalar(\"loss/testing\", test_loss, epoch)\n",
        "    writer.flush()\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86cb2d1b-f9a2-41b1-b4d4-456454b41f44",
      "metadata": {
        "id": "86cb2d1b-f9a2-41b1-b4d4-456454b41f44"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "torch.save(model.state_dict(), f\"/content/drive/MyDrive/ringo/autoaim_{run}.pt\")\n",
        "\n",
        "torch.save(model, f\"/content/drive/MyDrive/ringo/autoaim_{run}_full_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8778da8-0b68-4512-a959-8cfbb2900bf5",
      "metadata": {
        "id": "e8778da8-0b68-4512-a959-8cfbb2900bf5"
      },
      "outputs": [],
      "source": [
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T4wzt7xrNt82"
      },
      "id": "T4wzt7xrNt82",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}